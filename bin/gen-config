#!/usr/bin/env bash

echo Welcome to gen-config for Getup Engine
echo

libDir=$(dirname ${0})

if [ $# -lt 1 -o $# -gt 2 -o "$1" == "-h" -o "$1" == "--help" ]; then
    echo "Usage: $0 [cluster-name|dir] <outputfile>"
    echo "Where"
    echo "  cluster-name    $PWD/state/[cluster-name]"
    echo "  dir-name        full path for existing dir"
    echo "  <outputfile>    optional output file, (default: [state-dir]/getupengine.env)"
    exit 1
fi

source $libDir/gen-config-lib.sh

if [ -d "state/$1" ]; then
    stateDir="$PWD/state/$1"
elif [ -d "$1" ]; then
    stateDir="$1"
elif ! grep -q / <<<$1; then
    echo "Creating state dir $PWD/state/$1"
    stateDir="$PWD/state/$1"
    mkdir -p $stateDir
    echo
else
    echo "Invalid cluster-name or state dir: $1"
    exit 1
fi

echo State dir is $stateDir

outputFile=${2:-$stateDir/getupengine.env}

if [ -e $outputFile ]; then
   source $outputFile
fi

export NAME=${stateDir##*/}

tempOutputFile="${outputFile}.$$"
exec 3>${tempOutputFile}

################################################################

ex "# Auto-generated by $0 - $(LC_ALL=C date -u)"
ex NAME=$NAME
sel PROVIDER aws azure gce

if provider_is gce && ! ask 'GCE Support is incomplete. You MUST known what you are doing... Continue anyway?' false; then
    exit
fi

ex CLUSTER_ID="${CLUSTER_ID:-owned}"

if provider_is aws; then
    rd AWS_ACCESS_KEY_ID ${AWS_ACCESS_KEY_ID}
    rd AWS_SECRET_ACCESS_KEY ${AWS_SECRET_ACCESS_KEY}
    sel AWS_DEFAULT_REGION ${awsRegions[@]}

    avalZones=( $(list_aws_availability_zones $AWS_DEFAULT_REGION) )
    mult AWS_AVAILABILITY_ZONES "${avalZones[@]}"
    AZ_LIST=( ${AWS_AVAILABILITY_ZONES[*]} )
    AZ_COUNT=${#AZ_LIST[*]}

    hostedZones=""
    while read line; do
        hostedZones+="$(awk '{printf("%s:%s", $1, $2)}' <<<$line) "
    done < <(list_aws_hosted_zones)

    if [ -z "${hostedZones}" ]; then
        echo "No Route53 Hosted Zones found. Please provide external zone:"
        rd CLUSTER_ZONE $CLUSTER_ZONE
    else
        # Cluster zone
        sel _CLUSTER_AWS_ZONE ${hostedZones[@]}
        ex AWS_CLUSTER_ZONE_ID=${_CLUSTER_AWS_ZONE%:*}
    fi
    ex CLUSTER_ZONE=${_CLUSTER_AWS_ZONE#*:}

    # Apps zone
    sel _APPS_AWS_ZONE ${hostedZones[@]}

    ex AWS_APPS_ZONE_ID=${_APPS_AWS_ZONE%:*}
    if [ "${AWS_CLUSTER_ZONE_ID}" != "${AWS_APPS_ZONE_ID}" ]; then
        ex APPS_ZONE=${_APPS_AWS_ZONE#*:}
    else
        ex "APPS_ZONE=${CLUSTER_ZONE}"
    fi

    keyPairs=( $(get_aws_key_pairs) )
    if [ -z ${keyPairs} ]; then
        echo "No AWS SSH Key Pair found on region $AWS_DEFAULT_REGION"
        echo "Please upload/create at least one key pair and try again"
        exit 1
    fi
    sel AWS_KEY_NAME ${keyPairs[*]}

elif provider_is azure; then

    rd AZURE_SUBSCRIPTION_ID
    rd AZURE_RESOURCE_GROUP
    sel AZURE_LOCATION ${azureRegions[@]}

    if ask "Create a new Service Principal now?" false; then
        az login
        az group create -n $AZURE_RESOURCE_GROUP -l $AZURE_LOCATION
        az ad sp create-for-rbac --role=Contributor \
            --scopes=/subscriptions/${AZURE_SUBSCRIPTION_ID}/resourceGroups/${AZURE_RESOURCE_GROUP} > $STATE_DIR/servicePrincipal.json
        cat $STATE_DIR/servicePrincipal.json
        rd AZURE_CLIENT_ID $(jp --unquoted appId < $STATE_DIR/servicePrincipal.json)
        rd AZURE_CLIENT_SECRET $(jp --unquoted password < $STATE_DIR/servicePrincipal.json)
        rd AZURE_TENANT_ID $(jp --unquoted tenant < $STATE_DIR/servicePrincipal.json)
    else
        echo "You can use an existing Service Principal or  manually create one by running:"
        echo " az login"
        echo " az group create -n $AZURE_RESOURCE_GROUP -l $AZURE_LOCATION  ## if not exists yet"
        echo " az ad sp create-for-rbac --role=Contributor --scopes=/subscriptions/${AZURE_SUBSCRIPTION_ID}/resourceGroups/${AZURE_RESOURCE_GROUP}"
        ask 'Continue?' true || true

        rd AZURE_CLIENT_ID
        rd AZURE_CLIENT_SECRET
        rd AZURE_TENANT_ID
    fi

    rd CLUSTER_ZONE
    rd APPS_ZONE ${CLUSTER_ZONE}

elif provider_is gce; then
    ex GCE_CLUSTER_PREFIX=${NAME}
    ex GOOGLE_CREDENTIALS=/state/google.json
    rd GOOGLE_REGION

    rd CLUSTER_ZONE
    rd APPS_ZONE
    rd GOOGLE_PROJECT
    rd REGISTRY_GCE_BUCKET_NAME
    #rd REGISTRY_GCE_KEY_FILE
fi

rd MASTER_COUNT $AZ_COUNT
rd INFRA_COUNT $AZ_COUNT
rd APP_COUNT $((AZ_COUNT * 2))

if provider_is aws; then
    rd AWS_INSTANCE_BASTION ${AWS_INSTANCE_BASTIONL:-t2.small}
    rd AWS_INSTANCE_MASTER ${AWS_INSTANCE_MASTER:-m4.large}
    rd AWS_INSTANCE_INFRA ${AWS_INSTANCE_INFRA:-m4.xlarge}
    rd AWS_INSTANCE_APP ${AWS_INSTANCE_APP:-m4.xlarge}
    ex HIGH_PERF_DISK_TYPE="io1"
    ex OPENSHIFT_STORAGECLASS_NAME="gp2"
    ex OPENSHIFT_MONITORING_STORAGE_TYPE="pvc"
    ex OPENSHIFT_METRICS_STORAGE_KIND="dynamic"
    ex OPENSHIFT_LOGGING_STORAGE_KIND="dynamic"
    ex INSTALL_BACKUP=true

elif provider_is azure; then
    rd AZURE_OS_OFFER centos
    rd AZURE_INSTANCE_BASTION ${AZURE_INSTANCE_BASTION:-Standard_DS2_v2}
    rd AZURE_INSTANCE_MASTER ${AZURE_INSTANCE_MASTER:-Standard_DS4_v2}
    rd AZURE_INSTANCE_INFRA ${AZURE_INSTANCE_INFRA:-Standard_DS4_v2}
    rd AZURE_INSTANCE_APP ${AZURE_INSTANCE_APP:-Standard_DS4_v2}
    ex HIGH_PERF_DISK_TYPE="Premium_LRS"
    ex OPENSHIFT_STORAGECLASS_NAME="standard-lrs"
    ex OPENSHIFT_MONITORING_STORAGE_TYPE="pvc"
    ex OPENSHIFT_METRICS_STORAGE_KIND="dynamic"
    ex OPENSHIFT_LOGGING_STORAGE_KIND="dynamic"
    ex INSTALL_BACKUP=true

elif provider_is gce; then
    # TODO: we dont provision GCE yet
    ex HIGH_PERF_DISK_TYPE="pd-ssd"
    ex OPENSHIFT_STORAGECLASS_NAME="pd-standard"
    ex OPENSHIFT_MONITORING_STORAGE_TYPE="pvc"
    ex OPENSHIFT_METRICS_STORAGE_KIND="dynamic"
    ex OPENSHIFT_LOGGING_STORAGE_KIND="dynamic"
    ex INSTALL_BACKUP=true
    rd GETUPCLOUD_BACKUP_GCE_ZONE
    ask 'Press ENTER and paste the content of a valid service-account with enough permissions to manage disk snapshots.'
    cat > $stateDir/gce-service-account.json
    ex GETUPCLOUD_BACKUP_GCE_SERVICE_ACCOUNT_JSON="/state/gce-service-account.json"
fi

if ask "Use high performance ($HIGH_PERF_DISK_TYPE) disks where applicable?" ${USE_HIGH_PERF_DISKS:-true}; then
    ex USE_HIGH_PERF_DISKS=true
else
    ex USE_HIGH_PERF_DISKS=false
fi

pw OPENSHIFT_MASTER_SESSION_AUTH_SECRET 64
pw OPENSHIFT_MASTER_SESSION_ENCRYPTION_SECRET 32

if ask "Install Openshift Metrics (Hawkular)?" ${INSTALL_METRICS:-true}; then
    ex INSTALL_METRICS=true
    ex OPENSHIFT_METRICS_STORAGE_CLASS_NAME=$OPENSHIFT_STORAGECLASS_NAME
else
    ex INSTALL_METRICS=false
fi

if ask "Install Openshift Monitoring (Prometheus + Alertmanager)?" ${INSTALL_MONITORING:-true}; then
    ex INSTALL_MONITORING=true
    #sel OPENSHIFT_MONITORING_STORAGE_CLASS_NAME ${AZ_LIST[*]}
    ex OPENSHIFT_MONITORING_STORAGE_CLASS_NAME=${OPENSHIFT_STORAGECLASS_NAME}
#    rd OPENSHIFT_MONITORING_RETENTION 8w

    rd GETUPCLOUD_PAGER_DUTY_SERVICE_KEY

    if ask "Enable Alertmanager Zabbix Webhook?" ${ZABBIX_ENABLED:-false}; then
        ex ZABBIX_ENABLED=true
        rd ZABBIX_SERVER_HOST
        rd ZABBIX_SERVER_PORT 10051
    else
        ex ZABBIX_ENABLED=false
    fi
else
    ex INSTALL_MONITORING=false
fi

if ask "Install Openshift Logging (EFK)?" ${INSTALL_LOGGING:-true}; then
    ex INSTALL_LOGGING=true
    ex OPENSHIFT_LOGGING_CURATOR_DEFAULT_DAYS=30
    ex OPENSHIFT_LOGGING_CURATOR_DEFAULT_DAYS_OPS=30
    ex OPENSHIFT_LOGGING_STORAGE_CLASS_NAME=$OPENSHIFT_STORAGECLASS_NAME
else
    ex INSTALL_LOGGING=false
fi

if ask "Install Openshift Default ImageStreams & Templates?" ${INSTALL_EXAMPLES:-true}; then
    ex INSTALL_EXAMPLES=true
else
    ex INSTALL_EXAMPLES=false
fi

if ask 'Integrate with slack (error messages and prometheus alerts)?' ${GETUPCLOUD_OBSERVER_INSTALL:-false}; then
    ex INSTALL_OBSERVER=true
    rd GETUPCLOUD_SLACK_OPERATIONS_WEBHOOK
    rd GETUPCLOUD_SLACK_OPERATIONS_CHANNEL "#$NAME-errors"
    rd GETUPCLOUD_SLACK_TOKEN
else
    ex INSTALL_OBSERVER=false
    ex GETUPCLOUD_SLACK_OPERATIONS_CHANNEL=""
    ex GETUPCLOUD_SLACK_OPERATIONS_WEBHOOK=""
    ex GETUPCLOUD_SLACK_TOKEN=""
fi

rd GETUPCLOUD_VENDOR_NAME getup
rd GETUPCLOUD_VENDOR_TITLE "Getup Cloud"
rd GETUPCLOUD_VENDOR_NAMESPACE ${GETUPCLOUD_VENDOR_NAME}.io

if ask 'Install Web Console?' true; then
    ex INSTALL_CONSOLE=true

    if ask 'Enable web console billing section?' true; then
        ex GETUPCLOUD_CONSOLE_ENABLE_MODULE_BILLING=true
    else
        ex GETUPCLOUD_CONSOLE_ENABLE_MODULE_BILLING=false
    fi

    if ask 'Allow web console to show offer prices?' true; then
        ex GETUPCLOUD_CONSOLE_ENABLE_MODULE_PRICES=true
    else
        ex GETUPCLOUD_CONSOLE_ENABLE_MODULE_PRICES=false
    fi

    if ask 'Customize console links?' false; then
        cp -fv ansible/roles/getup-console/files/urls.json $stateDir/
        $EDITOR $stateDir/urls.json
        ex GETUPCLOUD_CONSOLE_URLS_PATH=$stateDir/urls.json
    else
        ex GETUPCLOUD_CONSOLE_URLS_PATH=""
    fi

    ex GETUPCLOUD_ROUTER_EXTERNAL_IPS=""
else
    ex INSTALL_CONSOLE=false
fi

if ask 'Install Billing Backend?' true; then
    ex GETUPCLOUD_INSTALL_BILLING=true
else
    ex GETUPCLOUD_INSTALL_BILLING=false
fi

sel _EMAIL_BACKEND_TYPE None SMTP Mailgun
case $_EMAIL_BACKEND_TYPE in
    SMTP)
        ex GETUPCLOUD_API_EMAIL_BACKEND='django.core.mail.backends.smtp.EmailBackend'
        rd GETUPCLOUD_API_SMTP_HOSTNAME
        rd GETUPCLOUD_API_SMTP_USERNAME
        rd GETUPCLOUD_API_SMTP_PASSWORD
    ;;
    Mailgun)
        ex GETUPCLOUD_API_EMAIL_BACKEND='django_mailgun.MailgunBackend'
        rd GETUPCLOUD_API_MAILGUN_ACCESS_KEY
    ;;
    *) ex GETUPCLOUD_API_EMAIL_BACKEND='django.core.mail.backends.console.EmailBackend'
esac

if ask 'Enable user signup endpoint?' false; then
    ex GETUPCLOUD_API_ENABLE_SIGNUP=True
else
    ex GETUPCLOUD_API_ENABLE_SIGNUP=False
fi

sel _VALIDATE_USER_ACCOUNT_WHEN_USER 'Signup' 'Confirm Email' 'Add Credit Card'
case "$_VALIDATE_USER_ACCOUNT_WHEN_USER" in
    "Signup") ex GETUPCLOUD_API_VALIDATE_ACCOUNT=signup;;
    "Confirm Email") ex GETUPCLOUD_API_VALIDATE_ACCOUNT=confirm_email;;
    "Add Credit Card") ex GETUPCLOUD_API_VALIDATE_ACCOUNT=set_payment_method
esac

if ask 'Enable Zendesk auth integration?' false; then
    rd GETUPCLOUD_ZENDESK_DOMAIN ${VENDOR_NAME}.zendesk.com
    rd GETUPCLOUD_ZENDESK_TOKEN
else
    ex GETUPCLOUD_ZENDESK_DOMAIN=''
    ex GETUPCLOUD_ZENDESK_TOKEN=''
fi

ex GETUPCLOUD_API_DATABASE_ENGINE=mysql
ex GETUPCLOUD_API_DATABASE_HOSTNAME=mysql-api
ex GETUPCLOUD_API_DATABASE_NAME=getup
ex GETUPCLOUD_API_DATABASE_USERNAME=getup
pw GETUPCLOUD_API_DATABASE_PASSWORD 24
pw GETUPCLOUD_API_DJANGO_SECRET_KEY 64
ex GETUPCLOUD_API_TRUSTED_DOMAINS=""

ex GETUPCLOUD_USAGE_DATABASE_HOSTNAME=mysql-usage
ex GETUPCLOUD_USAGE_DATABASE_NAME=usage
ex GETUPCLOUD_USAGE_DATABASE_USERNAME=getup
pw GETUPCLOUD_USAGE_DATABASE_PASSWORD 24

ex GETUPCLOUD_API_ADMIN_USERNAME=admin@${CLUSTER_ZONE}
pw GETUPCLOUD_API_ADMIN_PASSWORD 9
ex GETUPCLOUD_API_IMPERSONATE_USERNAME=impersonate@${CLUSTER_ZONE}
pw GETUPCLOUD_API_IMPERSONATE_PASSWORD 9
ex GETUPCLOUD_API_DEFAULT_CURRENCY=USD

echo

exec 3>&-

if [ -e ${outputFile} ]; then
   bkpFile="${outputFile}.$(date +%s).bkp"
   echo "Creating backup ${bkpFile}"
   cp -f ${outputFile} ${bkpFile}
fi

mv -f ${tempOutputFile} ${outputFile}
echo "Generated file $outputFile"
