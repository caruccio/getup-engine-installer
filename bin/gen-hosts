#!/bin/bash

# this file should be sourced

hosts_in=${1}
if [ $# -gt 1 ]; then
    hosts_extra_in=${2}
else
    hosts_extra_in=""
fi

# default basic configs
envsubst < ${hosts_in}

echo
echo "# Auto generated by $0"
echo "# $(date)"
echo

if [ "${stage}" == 'install' ]; then
    echo openshift_install_examples=true
else
    echo openshift_install_examples=false
fi

if [ -v CLUSTER_NETWORK_CIDR ]; then
    echo "osm_cluster_network_cidr=${CLUSTER_NETWORK_CIDR}"
fi

if [ -v SERVICE_NETWORK_CIDR ]; then
    echo "openshift_portal_net=${SERVICE_NETWORK_CIDR}"
fi

# Build master named certs config

if gen-certificate-config ${CLUSTER_ZONE} openshift_master_named_certificates console.${CLUSTER_ZONE} ${API_ENDPOINT} ${API_ENDPOINT_INTERNAL} ${EXTRA_CLUSTER_NAMES}; then
    check-certificate ${CLUSTER_ZONE} "${CERTS_DIR}/${CLUSTER_ZONE}.crt"
#else
#    sleep 3
fi

# Build router named certs config

if gen-certificate-config ${APPS_ZONE} openshift_hosted_router_certificate; then
    check-certificate ${APPS_ZONE} "${CERTS_DIR}/${APPS_ZONE}.crt"
#else
#    sleep 3
fi


case "${PROVIDER}" in
    aws)
        cat <<-EOF
			openshift_cloudprovider_kind='${PROVIDER}'
			openshift_cloudprovider_aws_access_key='${AWS_ACCESS_KEY_ID}'
			openshift_cloudprovider_aws_secret_key='${AWS_SECRET_ACCESS_KEY}'

			openshift_storageclass_parameters="{'type':'gp2','encrypted':'false'}"

			# AWS S3
			# S3 bucket must already exist.
			openshift_hosted_registry_storage_s3_encrypt=false
			#openshift_hosted_registry_storage_s3_kmskeyid=aws_kms_key_id
			openshift_hosted_registry_storage_s3_accesskey='${REGISTRY_AWS_ACCESS_KEY_ID}'
			openshift_hosted_registry_storage_s3_secretkey='${REGISTRY_AWS_SECRET_ACCESS_KEY}'
			openshift_hosted_registry_storage_s3_bucket='${REGISTRY_AWS_BUCKET_NAME}'
			openshift_hosted_registry_storage_s3_region='${REGISTRY_AWS_REGION}'
			openshift_hosted_registry_storage_s3_chunksize=26214400
			openshift_hosted_registry_storage_s3_rootdirectory='/registry'

			getupcloud_backup_storage_s3_accesskey="${GETUPCLOUD_BACKUP_STORAGE_S3_ACCESSKEY}"
			getupcloud_backup_storage_s3_secretkey="${GETUPCLOUD_BACKUP_STORAGE_S3_SECRETKEY}"
			getupcloud_backup_storage_s3_bucket="${GETUPCLOUD_BACKUP_STORAGE_S3_BUCKET}"
			getupcloud_backup_storage_s3_region="${GETUPCLOUD_BACKUP_STORAGE_S3_REGION}"
			getupcloud_backup_storage_s3_rootdirectory="${GETUPCLOUD_BACKUP_STORAGE_S3_ROOTDIRECTORY}"

EOF
    ;;

    azure)
        cat <<-EOF
			openshift_cloudprovider_kind='${PROVIDER}'
			openshift_cloudprovider_azure_tenant_id='${AZURE_TENANT_ID}'
			openshift_cloudprovider_azure_subscription_id='${AZURE_SUBSCRIPTION_ID}'
			openshift_cloudprovider_azure_client_id='${AZURE_CLIENT_ID}'
			openshift_cloudprovider_azure_client_secret='${AZURE_CLIENT_SECRET}'
			openshift_cloudprovider_azure_resource_group='${AZURE_RESOURCE_GROUP}'
			openshift_cloudprovider_azure_location='${AZURE_LOCATION}'

			# Configure controller arguments
			osm_controller_args={'cloud-config':['/etc/origin/cloudprovider/azure.conf'],'cloud-provider':['azure'],'resource-quota-sync-period': ['15s']}

			# Configure api server arguments
			osm_api_server_args={'cloud-config':['/etc/origin/cloudprovider/azure.conf'],'cloud-provider':['azure']}

			openshift_storageclass_parameters="{'kind':'managed','storageaccounttype':'Standard_LRS'}"
			openshift_storageclass_provisioner='azure-disk'

			# Azure Blob
			# A Blob Storage must already exist.
			openshift_hosted_registry_storage_azure_blob_accountname='${REGISTRY_AZURE_ACCOUNT_NAME}'
			openshift_hosted_registry_storage_azure_blob_accountkey='${REGISTRY_AZURE_ACCESS_KEY}'
			openshift_hosted_registry_storage_azure_blob_container='${REGISTRY_AZURE_CONTAINER}'
			openshift_hosted_registry_storage_azure_blob_realm='core.windows.net'

			getupcloud_backup_storage_azure_account_name="${GETUPCLOUD_BACKUP_STORAGE_AZURE_ACCOUNT_NAME}"
			getupcloud_backup_storage_azure_account_key="${GETUPCLOUD_BACKUP_STORAGE_AZURE_ACCOUNT_KEY}"
			getupcloud_backup_storage_azure_container="${GETUPCLOUD_BACKUP_STORAGE_AZURE_CONTAINER}"
EOF
    ;;

    gce)
        cat <<-EOF
			openshift_cloudprovider_kind='${PROVIDER}'
			openshift_gcp_project='${GCE_PROJECT_ID}'
			openshift_gcp_prefix='${GCE_CLUSTER_PREFIX}'
			openshift_gcp_multizone=True

			openshift_storageclass_parameters="{'type':'pd-ssd'}"

			# GCE
			# A GCS bucket must already exist.
			openshift_hosted_registry_storage_gcs_bucket='${REGISTRY_GCS_BUCKET_NAME}'
			openshift_hosted_registry_storage_gcs_keyfile='${GOOGLE_CREDENTIALS}'
			openshift_hosted_registry_storage_gcs_rootdirectory=/registry

			getupcloud_backup_gce_zone='${GETUPCLOUD_BACKUP_GCE_ZONE}'
			getupcloud_backup_gce_service_account_json='${GETUPCLOUD_BACKUP_GCE_SERVICE_ACCOUNT_JSON}'
			getupcloud_backup_gcs_bucket='${GETUPCLOUD_BACKUP_GCS_BUCKET}'
EOF
    ;;

    *)
        echo "openshift_cloudprovider_kind=''"
esac
echo

if [ -f "${GETUPCLOUD_CONSOLE_URLS_PATH}" ]; then
    echo getupcloud_console_urls_path=${GETUPCLOUD_CONSOLE_URLS_PATH}
fi

if [ -n "${GETUPCLOUD_CONSOLE_INDEX}" ]; then
    echo getupcloud_console_index=${GETUPCLOUD_CONSOLE_INDEX}
fi

# extra configs
if [ -r "${hosts_extra_in}" ]; then
    echo "# $hosts_extra_in"
    envsubst < ${hosts_extra_in}
    echo
fi

# host groups
function openshift_host()
{
    local _node=$1
    if [ $PROVIDER == 'azure' ]; then
        local _host=${_node}
    else
        local _host=${_node}${INTERNAL_DOMAIN_SUFFIX}
    fi
    shift
    echo "$_node openshift_public_hostname=\"$_host\" openshift_hostname=\"$_host\" ${@}"
}

function server_name()
{
    local privateName=$1

    if [ $PROVIDER == aws ]; then
        if ! [ -e /tmp/terraform.tfstate ]; then
            ( cd /getup-engine/terraform/aws && ${TERRAFORM_BIN} state pull > /tmp/terraform.tfstate )
        fi
        /getup-engine/bin/get-instance-tag $privateName Name < /tmp/terraform.tfstate || echo ${privateName%%.*}

    #elif [ $PROVIDER == azure ]; then
    #elif [ $PROVIDER == azure ]; then

    else
        echo ${privateName%%.*}
    fi
}

echo
echo '[masters]'
for master in ${MASTER_HOSTNAMES}; do
    openshift_host $master
done

echo
echo '[etcd]'
for master in ${MASTER_HOSTNAMES}; do
    openshift_host $master
done

if [ "${stage}" == 'scaleup' ]; then

    OLD_NODES="$(ansible -i $HOSTS_FILE --list-hosts nodes | grep -v 'hosts (.*)')"

    # copy [nodes] from current hosts files
    echo
    sed -ne '/^\s*\[nodes\]/,/^\[/p' $HOSTS_FILE

    echo Searching for new nodes >&2
    echo
    echo '[new_nodes]'

    NEW_INFRA_NODES=""

    for infra in ${INFRA_HOSTNAMES}; do
        if ! grep -wq $infra <<<$OLD_NODES; then
            NEW_INFRA_NODES+=" $infra"
        fi
    done

    if [ -n "$NEW_INFRA_NODES" ]; then
        echo Found new infra nodes: $NEW_INFRA_NODES >&2

        echo
        echo '# Infra Nodes'
        if [ -n "${NEW_INFRA_NODES}" ]; then
            for node in ${NEW_INFRA_NODES}; do
                openshift_host $node "openshift_node_group_name=\"node-config-infra\" openshift_schedulable=false openshift_node_labels=\"{'color':'green','role':'infra','region':'infra','zone':'default','server_name':'$(server_name $node)'}\""
            done
        fi
    fi

    NEW_APP_NODES=""

    for app in ${APP_HOSTNAMES}; do
        if ! grep -wq $app <<<$OLD_NODES; then
            NEW_APP_NODES+=" $app"
        fi
    done

    if [ -n "$NEW_APP_NODES" ]; then
        echo Found new app nodes: $NEW_APP_NODES >&2
        echo
        echo '# App Nodes'
        if [ -n "${NEW_APP_NODES}" ]; then
            for node in ${NEW_APP_NODES}; do
                openshift_host $node "openshift_node_group_name=\"node-config-compute\" openshift_schedulable=false openshift_node_labels=\"{'color':'green','role':'app','region':'primary','zone':'default', 'builder':'true', 'server_name':'$(server_name $node)'}\""
            done
        fi
    fi
else
    echo
    echo '[nodes]'

    echo
    echo '# MasterNodes'
    for master in ${MASTER_HOSTNAMES}; do
        openshift_host $master "openshift_node_group_name=\"node-config-master\" openshift_node_labels=\"{'role':'master','region':'primary','zone':'default','server_name':'$(server_name $master)'}\""
    done

    echo
    echo '# Infra Nodes'
    for infra in ${INFRA_HOSTNAMES}; do
        openshift_host $infra "openshift_node_group_name=\"node-config-infra\" openshift_node_labels=\"{'role':'infra','region':'infra','zone':'default','server_name':'$(server_name $infra)'}\""
    done

    echo
    echo '# App Nodes'
    for app in ${APP_HOSTNAMES}; do
        openshift_host $app "openshift_node_group_name=\"node-config-compute\" openshift_node_labels=\"{'role':'app','region':'primary','zone':'default','builder':'true','server_name':'$(server_name $app)'}\""
    done

    echo
    echo '[new_nodes] # placeholder'
fi

if ! [ -e /tmp/terraform.tfstate ]; then
    rm -f /tmp/terraform.tfstate
fi
